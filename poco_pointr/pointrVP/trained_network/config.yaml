optimizer : {
  type: AdamW,
  kwargs: {
  lr : 0.0001, 
  weight_decay : 0.0005
}}

scheduler: {
  type: LambdaLR,
  kwargs: {
  decay_step: 21,
  lr_decay: 0.9,
  lowest_decay: 0.02  # min lr = lowest_decay * lr
}}

bnmscheduler: {
  type: Lambda,
  kwargs: {
  decay_step: 21,
  bn_decay: 0.5,
  bn_momentum: 0.9,
  lowest_decay: 0.01
}}

dataset : {
  root_dir : '/home/media/Documents/PoinTr/COSC_random',
  train_split: '/home/media/Documents/PoinTr/Name_of_Trainning_Objects.txt',
  test_split: '/home/media/Documents/PoinTr/Name_of_Test_Objects.txt',
}     
            
model : {
    NAME: COSC, 
    num_query: 512, 
    num_points: 2048,
    center_num: [512, 256],
    global_feature_dim: 1024, 
    encoder_type: graph,
    decoder_type: fc,
    output_dim: 32,
    encoder_config: {
      embed_dim: 384,
      depth: 6,
      num_heads: 6,
      k: 8,
      n_group: 2,
      mlp_ratio: 2.,
      block_style_list: ['attn-graph', 'attn', 'attn', 'attn', 'attn', 'attn'], 
      combine_style: 'concat',
    },
    vs_config: {
      input_size: 32,
      hidden_size: 64,
      num_layers: 4,
      num_heads: 4,
      dropout: 0.1,
    }
}
  
# total_bs : 8
total_bs : 8
step_per_update : 1
max_epoch : 600

consider_metric: CDL2

threshold_gamma: 0.5
lambda_for_1: 1.5
do_sample: False